{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faaa8956-e700-49f6-8c8d-dd889b1e64fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Final Project by Abay Jumabayev\n",
    "\n",
    "## Topic: Toxicity detection\n",
    "## Description: \n",
    "I want to predict toxicity in the comments. I found a [data](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data) with human-labeled information about toxicity. The data contains text from Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n",
    "* toxic\n",
    "* severe_toxic\n",
    "* obscene\n",
    "* threat\n",
    "* insult\n",
    "* identity_hate\n",
    "I am going to create a model that will predict whether the message is toxic (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion).\n",
    "\n",
    "## Steps:\n",
    "1. I am going to do a preprocessing.\n",
    "\n",
    "2. I will use three types of word embeddings:\n",
    "* TF-IDF\n",
    "* Word2Vec\n",
    "* GloVe\n",
    "\n",
    "3. For each of word embeddings, I will train six models:\n",
    "* Linear regression\n",
    "* Logistic regression\n",
    "* Naive Bayes\n",
    "* Decision Tree\n",
    "* KNN\n",
    "* SVC\n",
    "\n",
    "Overall, I will have $3*6=18$ different models and choose one which has the highest metric score. My metric score will be precision $ = \\frac{tp}{tp + fp}$. I want to decrease type II error, that is to decrease false positives. I don't want model to make errors and predict non-toxic comment as toxic.\n",
    "\n",
    "4. I will apply trained model to Dota 2 in-game chats. \n",
    "Dota 2 community is assumed toxic and I want to test whether this is true. I assume here that Dota 2 chat messages are similar to the Wikipedia comments as they are written online, seen by people that do not know each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6af6b-78bc-4177-8712-c246bafa111b",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n",
    "Let's start with preprocessing. First thing is to load the data and look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20dca8fa-ac04-4f19-b263-a0678135682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, LancasterStemmer \n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b460f2ea-aca2-48dc-bcff-836f27d1a10f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73606f-7f87-4f4e-a1df-e166b1249bae",
   "metadata": {},
   "source": [
    "I don't need *id*, and other types of toxicity except *toxic* and *severe_toxic*. Let's get rid of non-necessary columns and look how balanced our data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b367e0-ed22-4ae9-9f36-e999bff87662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic  severe_toxic\n",
       "0      0               144277\n",
       "1      0                13699\n",
       "       1                 1595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns\n",
    "df = df.drop(['id', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1)\n",
    "\n",
    "# look how balanced the data is\n",
    "df.groupby(['toxic', 'severe_toxic']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a2f72-169c-4b04-bfec-f570fd75083e",
   "metadata": {},
   "source": [
    "Out of 159,571 comments, 15,294 (about 10% of the data) are toxic and 1595 (about 1% of the data) are severe toxic messages.\n",
    "\n",
    "The data is very unbalanced, that is why I will need to stratify data when splitting data\n",
    "\n",
    "Now, I am switching to text preprocessing. I will define a function that takes text as input an does the following:\n",
    "* replaces all non-alphanumeric characters with spaces\n",
    "* replaces 3+ consecutive letters to one. e.g. looooove -> love\n",
    "* removes all emails\n",
    "* removes all urls\n",
    "* replaces all letters to lower case\n",
    "* removes stopwords (nltk stopwords)\n",
    "* removes words with digits\n",
    "* conducts a lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b27d227-f99f-4b6c-9584-51c1931f8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the stopword list provided by the NLTK library\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac80268-82ca-4696-9f10-0975051b7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', ' ', text) #remove all non‚Äêalphanumeric characters except white space\n",
    "    text = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", text) #replace 3+ consecutive letters to 1 (loooovvvve -> love)\n",
    "    text = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", text) # remove emails\n",
    "    text = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , text) # remove urls\n",
    "    words = word_tokenize(text.lower())\n",
    "    tokens = [word for word in words if word not in stop_words]\n",
    "    tokens = [token for token in tokens if not any(c.isdigit() for c in token)] #remove everything containing digits\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lematized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    preprocessed_text = ' '.join(tokens_lematized)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c2c720d-f65d-482f-888d-468c6bc5d7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: preprocessing_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10acec-110d-4515-a2d4-9a51a5749884",
   "metadata": {},
   "source": [
    "Now as the preprocessing done, we can save our data to pickle so we can easily load it later"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09bec0dd-cad6-41ff-8490-a9f9efffaafb",
   "metadata": {},
   "source": [
    "# to save prepocessed text as pickle \n",
    "import pickle\n",
    "with open(\"comment_data.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(df, fp)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f0ee87d-0b4e-4bcb-92c7-18a4e8a54b4d",
   "metadata": {},
   "source": [
    "# load pickle here\n",
    "import pickle\n",
    "\n",
    "with open(\"comment_data.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    df2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb5902-a78a-4e94-a804-957cd3bfc38b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2.1 TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c350b9be-506d-4bba-8267-fe447ff1d4e5",
   "metadata": {},
   "source": [
    "For TF-IDF I think that *max_df* should not be set to any value because the comments are not related to each other and we will be analyzing each of them on being toxic.\n",
    "\n",
    "*min_df* is also should be set to 1, because as we saw, there are only 1% of severe toxic comments. By setting min df even to 1% we can get rid of important features that define toxicity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6d1721e-f44b-47fb-921b-492a1aec3455",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9748/3510276357.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer() \n",
    "tfidf = vectorizer.fit_transform(df.comment_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d616ee91-5442-44a3-8821-d9a3a02997f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1.1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0a3181a6-9b0d-4786-9ceb-97070f996ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, df['toxic'], test_size=0.2, random_state=1, stratify = df['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "224323d1-2347-4e72-9ce7-ecab50848818",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45f59c34-b5d6-4643-818d-dbc172fb81cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3fe3323-9053-4b27-a233-9811c026b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3980293-5051-40ea-8692-3a861305c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert continuous values to binary\n",
    "predictions[predictions >= 0.5] = 1\n",
    "predictions[predictions < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "082caccd-c1fd-4b80-b110-8847136c1403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     28856\n",
      "           1       0.52      0.58      0.55      3059\n",
      "\n",
      "    accuracy                           0.91     31915\n",
      "   macro avg       0.74      0.76      0.75     31915\n",
      "weighted avg       0.91      0.91      0.91     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7c3feeb-c9b6-4c9b-a4b5-0f39e9185214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27258  1598]\n",
      " [ 1294  1765]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1173696-6ea2-4c00-ac88-c8a4152bcd96",
   "metadata": {},
   "source": [
    "We can see that accuracy is high, but that's because most of the data has the class 0.\n",
    "\n",
    "The metrics of interest, precision is 0.52 which is not that good. Let's try changing the threshold by which we assign the class (used 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17ae990b-fdcc-4aae-b7ea-e9592f688cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     28856\n",
      "           1       0.57      0.48      0.52      3059\n",
      "\n",
      "    accuracy                           0.91     31915\n",
      "   macro avg       0.76      0.72      0.74     31915\n",
      "weighted avg       0.91      0.91      0.91     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_regressor.fit(X_train, y_train)\n",
    "predictions = linear_regressor.predict(X_test)\n",
    "\n",
    "# convert continuous values to binary\n",
    "predictions[predictions >= 0.6] = 1\n",
    "predictions[predictions < 0.6] = 0\n",
    "\n",
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b5fcf-8bb5-4f8d-9ab9-9d62c7edc7a6",
   "metadata": {},
   "source": [
    "The results are not good either, although we increased the precision from 0.52 to 0.57.\n",
    "\n",
    "Let's see how other models will perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a891be4-270d-4b62-aac8-755daaad5d29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1.2. Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8f53648-a0a1-4fb5-8569-7f265f31c6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regressor = LogisticRegression(random_state=0)\n",
    "\n",
    "logistic_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be5b65e1-e92c-4764-af83-78468b13c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a98bfcd-aa58-4e80-983d-77503a2934e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     28856\n",
      "           1       0.93      0.61      0.73      3059\n",
      "\n",
      "    accuracy                           0.96     31915\n",
      "   macro avg       0.94      0.80      0.86     31915\n",
      "weighted avg       0.96      0.96      0.95     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6911b96a-b95a-4a0c-b181-49eadb286ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28712   144]\n",
      " [ 1205  1854]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040505a-0f58-48e6-925f-b5190eb6c88d",
   "metadata": {},
   "source": [
    "Logistic regression with l2 penalty is doing a better job in classification than linear regression.\n",
    "\n",
    "Precision is now 0.93 and accuracy is 0.96 compared to 0.57 and 0.91 given by linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c98b0-f1cf-46d0-bffa-120faceb9333",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8695076c-f1cb-46e2-b33a-708ffe99bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     28856\n",
      "           1       0.75      0.61      0.67      3059\n",
      "\n",
      "    accuracy                           0.94     31915\n",
      "   macro avg       0.86      0.79      0.82     31915\n",
      "weighted avg       0.94      0.94      0.94     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB = BernoulliNB()\n",
    "\n",
    "NB.fit(X_train, y_train)\n",
    "predictions = NB.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55aa333c-ec1b-4575-bc3e-0587aa8762d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28252   604]\n",
      " [ 1206  1853]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656db64-2a44-4eb0-b56e-254f7a9e4b39",
   "metadata": {},
   "source": [
    "I used Bernoulli NB because this is the one which predicts boolean values.\n",
    "\n",
    "The precision is 0.75 which is worse than the one logistic regression had. Accuracy also dropped down a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171e942-589e-42bf-9476-8cf865c1f4fe",
   "metadata": {},
   "source": [
    "## 2.1.4 Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00c31647-bd61-428c-ac7b-36ae35594c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "470c05ca-3cb3-407e-ba26-e9f6855612a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': np.arange(1,10),\n",
    "             'criterion': ['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f1d4c6a-99c7-40a5-b693-1ab67324c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(tree, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "536a4bff-7164-400b-b37e-2c03502d9252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([1, 2, 3, 4, 5, 6, 7, 8, 9])})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9692fd51-239f-4b49-a5f6-d13a374e7daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 9}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95e67d-8656-474a-bd4d-e0804b97b750",
   "metadata": {},
   "source": [
    "Grid search found that gini criterion and a depth of 9 layers are the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9ffad43-5db4-4a22-966a-35c770167c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b723fe6-f7aa-41b3-915d-f7d0610915a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     28856\n",
      "           1       0.88      0.44      0.59      3059\n",
      "\n",
      "    accuracy                           0.94     31915\n",
      "   macro avg       0.91      0.72      0.78     31915\n",
      "weighted avg       0.94      0.94      0.93     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0137c57a-b132-4ba0-8e93-f46ebbfbbe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28680   176]\n",
      " [ 1705  1354]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67189f3-1801-40fc-862d-c4b5007760f3",
   "metadata": {},
   "source": [
    "Precision is quite high, however recall is too low. The model classifies many of toxic messages as non-toxic.\n",
    "\n",
    "Accuracy is 0.94. Still Logistic model is the best among the four."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fa0bd-81c3-4aaa-9475-8ba536ad0bc7",
   "metadata": {},
   "source": [
    "## 2.1.5 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d70a7c2d-427f-4f00-8ecc-ff1e20ec176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1713b89-6b1a-489e-be1c-72bbbeb053ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': [1,5,10,15,20,25,30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73464ee5-cd40-4034-9d1d-6a903827dac3",
   "metadata": {},
   "source": [
    "I decreased the size of param grid from 30 to 7 (by using this list [1,5,10,15,20,25,30]) because it takes a lot of time to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "006fcbae-6bc4-4261-8541-22c5a3fe00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab252c94-eb09-4ec4-9b12-de4b431734d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 5, 10, 15, 20, 25, 30]})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ddb8585-a87b-4b5b-a598-fa8af27ab209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a37bb360-1c93-4bc6-a85c-db86a7b50ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5cb3fee4-d8b7-4a30-8748-826c1ab8baee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     28856\n",
      "           1       0.73      0.27      0.39      3059\n",
      "\n",
      "    accuracy                           0.92     31915\n",
      "   macro avg       0.83      0.63      0.67     31915\n",
      "weighted avg       0.91      0.92      0.90     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e73e0b2-b599-4f79-adc6-696103a5b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28561   295]\n",
      " [ 2242   817]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8add1395-340d-4884-b79f-29bc585bb3bb",
   "metadata": {},
   "source": [
    "KNN with 1 neighbor provides not good results. recall is too low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1a590-6a8d-4f41-be04-dd3a593493f1",
   "metadata": {},
   "source": [
    "## 2.1.6 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8419a1cc-6675-4ef6-969a-0aeab0c4f31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     28856\n",
      "           1       0.88      0.69      0.77      3059\n",
      "\n",
      "    accuracy                           0.96     31915\n",
      "   macro avg       0.92      0.84      0.87     31915\n",
      "weighted avg       0.96      0.96      0.96     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "predictions = svc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9e77334b-ff9d-4040-90f6-53b1c9c64840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28556   300]\n",
      " [  952  2107]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b7caf-8710-40a0-a9b4-9d18a10288b1",
   "metadata": {},
   "source": [
    "SVC provides the highest accuarcy as well as logistic regression, but precision is lower (0.88).\n",
    "\n",
    "Overall, using TF-IDF, the best performance was computed with Logistic model (2.1.2), which has precision of 0.93 and accuracy of 0.96.\n",
    "\n",
    "Let's move to Word2Vec now and see whether this type of word embedding is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223d8a7-9fa1-4616-810d-7b10aa46577b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2.2 Word2Vec\n",
    "\n",
    "I am going to use SpaCy to get a pretrained model. This pretrained model will allow me to convert string to a vector of length 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "55c79968-61c2-4b12-bfb8-b892cf4b9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3fa73bef-c7e2-41e0-8bca-d4fc8135cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a text as input and returns a vector\n",
    "def get_vec(x):\n",
    "    doc = nlp(x)\n",
    "    vec = doc.vector\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bbdc1405-3c20-4c22-a064-27310ed76bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 24s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.033511575, 0.017874392, -0.12182923, 0.0465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.042986494, 0.22736022, -0.048771024, 0.053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.20488231, 0.004869846, -0.23974332, 0.0255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.03875695, 0.10936845, -0.21767448, 0.00962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.087694, 0.12292659, -0.1436986, 0.08244420...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  explanation edits made username hardcore metal...      0             0   \n",
       "1  aww match background colour seemingly stuck th...      0             0   \n",
       "2  hey man really trying edit war guy constantly ...      0             0   \n",
       "3  make real suggestion improvement wondered sect...      0             0   \n",
       "4                      sir hero chance remember page      0             0   \n",
       "\n",
       "                                                 vec  \n",
       "0  [0.033511575, 0.017874392, -0.12182923, 0.0465...  \n",
       "1  [-0.042986494, 0.22736022, -0.048771024, 0.053...  \n",
       "2  [-0.20488231, 0.004869846, -0.23974332, 0.0255...  \n",
       "3  [-0.03875695, 0.10936845, -0.21767448, 0.00962...  \n",
       "4  [-0.087694, 0.12292659, -0.1436986, 0.08244420...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df['vec'] = df['comment_text'].apply(lambda x: get_vec(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d3d01-0b9e-476f-aef5-e46456642d8d",
   "metadata": {},
   "source": [
    "Here we see how the *vec* column looks like. Each row in *vec* has a length of 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "946ef466-c4d5-40d0-9f78-9ec1cffa2d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 300)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['vec'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "X = np.concatenate(np.concatenate(X, axis = 0), axis = 0).reshape(-1, 300)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5dbe8e32-c70b-4853-bf3a-5922e5e2e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a91ae380-b4a2-4caf-95ea-bfb76c56862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb0f03-90aa-484b-ad1e-8fe126a45de3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2.1. Linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ae66049f-94b1-406d-9ec8-6ce5995b5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "82ef62e3-1265-47d2-9473-b9826dd890de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "linear_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1036bdcd-852d-4935-81b1-7e4b73903377",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e346be87-4293-4ae5-9702-b6ed51720b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert continuous values to binary\n",
    "predictions[predictions >= 0.5] = 1\n",
    "predictions[predictions < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76047120-ce22-4031-b5f6-c8a8a0695c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     28856\n",
      "           1       0.92      0.39      0.55      3059\n",
      "\n",
      "    accuracy                           0.94     31915\n",
      "   macro avg       0.93      0.69      0.76     31915\n",
      "weighted avg       0.94      0.94      0.93     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79a1e316-0a60-4954-bf21-59723bb021d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28755   101]\n",
      " [ 1874  1185]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac7b45-2991-4c53-b8cf-d2c720563565",
   "metadata": {},
   "source": [
    "Pecision and accuracy are quite high, but still worse that the model 2.1.2 Logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849bded7-b93d-42bc-b64c-e1264c0e3af3",
   "metadata": {},
   "source": [
    "## 2.2.2. Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f305824e-2894-4482-982d-6705f7b00c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regressor = LogisticRegression(random_state=0)\n",
    "%%time\n",
    "logistic_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1c9bc5f1-0585-4641-b34d-b6cf917a5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc0bf9c1-826b-44a7-9ec8-b1310feb273e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     28856\n",
      "           1       0.84      0.60      0.70      3059\n",
      "\n",
      "    accuracy                           0.95     31915\n",
      "   macro avg       0.90      0.79      0.84     31915\n",
      "weighted avg       0.95      0.95      0.95     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dafcc58c-067a-48b2-9674-a5a9ee64a570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28511   345]\n",
      " [ 1220  1839]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652de974-3625-4402-afcd-1d1f2ba49fb5",
   "metadata": {},
   "source": [
    "With word2vec precision decreases comparing to the logistic model 2.1.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cbc07-7f37-4ec9-b9d7-78e0bd9207dc",
   "metadata": {},
   "source": [
    "## 2.2.3 Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b7b591d-f322-4953-8d7d-cc0b731e8c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94     28856\n",
      "           1       0.47      0.78      0.59      3059\n",
      "\n",
      "    accuracy                           0.90     31915\n",
      "   macro avg       0.72      0.84      0.76     31915\n",
      "weighted avg       0.93      0.90      0.91     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB = BernoulliNB()\n",
    "%%time\n",
    "NB.fit(X_train, y_train)\n",
    "predictions = NB.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09dd0a8d-aac1-4f39-8e5b-3edf04d02be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26199  2657]\n",
      " [  673  2386]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93357e-9e60-443f-94ce-22aae62f5f44",
   "metadata": {},
   "source": [
    "The precision is very low. NB did a very bad job in predicting toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83c1a6-37d1-4109-b5c6-67ccf385d3fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2.4 Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fa24a4ba-1e16-40f5-885c-fc9d4108eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4cd16205-545d-4678-8431-461b56b960cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': np.arange(1,10),\n",
    "             'criterion': ['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "61f747a9-110a-4226-aecf-22dd3cd1947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(tree, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b9d890b-2468-47ab-8617-73e81e9f25fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([1, 2, 3, 4, 5, 6, 7, 8, 9])})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "af18478c-68de-48b2-ba54-5d26f19d7801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 8}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7c62b-6995-4347-a841-b84ce70ddf14",
   "metadata": {},
   "source": [
    "Grid search found that entropy criterion and a depth of 8 layers are the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aaeb62e9-452f-4c22-bde8-ce64ccb8c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0383b7c4-dfef-490b-beeb-812ceca68793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     28856\n",
      "           1       0.82      0.45      0.58      3059\n",
      "\n",
      "    accuracy                           0.94     31915\n",
      "   macro avg       0.88      0.72      0.77     31915\n",
      "weighted avg       0.93      0.94      0.93     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cccf65a2-4da2-47b1-b414-dd6aff038c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28541   315]\n",
      " [ 1670  1389]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd0cda-11ab-4a42-93e3-dd3be95e6a23",
   "metadata": {},
   "source": [
    "This model does not beat the model 2.1.2 as well. Although, the performance is not bad, precision is 0.82 and accuracy is 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65196510-2333-42d0-8795-9791e09f3553",
   "metadata": {},
   "source": [
    "## 2.2.5 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9f48c650-b966-414c-b347-4151e7543d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "432b9e46-1815-4876-971d-d56e5cae05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': [1,5,10,15,20,25,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0376cfb3-d4a2-4327-8f69-c5354f43a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a78ff9c5-cbcd-434a-9fe1-0d2be425b9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 5, 10, 15, 20, 25, 30]})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c8aef2d9-d337-48f0-8b29-b658032aa101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 20}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1b5a6ba8-f36d-4855-9d92-f29f2e928c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "824f776e-f286-4d14-92e2-ccd0748bddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     28856\n",
      "           1       0.84      0.54      0.66      3059\n",
      "\n",
      "    accuracy                           0.95     31915\n",
      "   macro avg       0.90      0.77      0.82     31915\n",
      "weighted avg       0.94      0.95      0.94     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aec6f59a-72cd-4a6d-a1ef-39917ccbbaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28545   311]\n",
      " [ 1398  1661]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe415148-fec9-4e9f-a925-2d32697e4670",
   "metadata": {},
   "source": [
    "KNN with 20 neighbors performed relatively good. Precision is not as good as the model 2.1.2 has."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331ca90-a3de-4019-9c98-586e6b37b819",
   "metadata": {},
   "source": [
    "## 2.2.6 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9bca405f-8c69-4099-941c-723ed9624d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     28856\n",
      "           1       0.80      0.40      0.53      3059\n",
      "\n",
      "    accuracy                           0.93     31915\n",
      "   macro avg       0.87      0.69      0.75     31915\n",
      "weighted avg       0.93      0.93      0.92     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "predictions = svc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d69fb518-cd17-46f4-82dd-cca8521332c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28553   303]\n",
      " [ 1838  1221]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff83a2c-a74f-4828-a562-fe86822d097e",
   "metadata": {},
   "source": [
    "SVC does not provide the best results. Precision is low (0.8)\n",
    "\n",
    "Overall, for Word2Vec the linear regression (2.2.1) had the highest precision of 0.92.\n",
    "\n",
    "Nevertheless, TF-IDF did a better job classifying toxic comments.\n",
    "\n",
    "Let's see how GloVe will help models perform "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a6a68-0129-4aa4-8a49-88f6103a424c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2.3 GloVe\n",
    "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space. (Read more [here](https://nlp.stanford.edu/projects/glove/))\n",
    "\n",
    "First, we need to load a GloVe vector. I will use the file `glove.6B.100d.txt`, which contains pre-trained word vectors from Wikipedia. You can download it [here](https://nlp.stanford.edu/data/glove.6B.zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e470950d-c320-4a75-a0dd-df9519db3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = dict()\n",
    "\n",
    "file = open('../../Inputs/glove/glove.6B.100d.txt', encoding='utf-8') # make sure you have the file and that the location is correct\n",
    "\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word  = values[0]\n",
    "    vectors = np.asarray(values[1:])\n",
    "    glove_vectors[word] = vectors\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa705e3-ca17-470e-b285-688b7ba1c26e",
   "metadata": {},
   "source": [
    "Now we need a function that will transform a string to a 100 length vector.\n",
    "Then we will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "68aa021a-b8ce-493a-b386-78ed178eb611",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_shape = 100\n",
    "\n",
    "def get_vec(x):\n",
    "    arr = np.zeros(vec_shape)\n",
    "    text = str(x).split() \n",
    "    if len(text)==0:\n",
    "        return arr\n",
    "    else:      \n",
    "        for t in text:\n",
    "            try:\n",
    "                vec = glove_vectors.get(t).astype(float)\n",
    "                arr = arr + vec\n",
    "            except:\n",
    "                pass      \n",
    "        arr = arr.reshape(1, -1)[0]\n",
    "\n",
    "        return arr/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9d4b2207-aeab-41ec-907b-514a7c5c9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['glo_vec'] = df['comment_text'].apply(lambda x: get_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fa6ad68b-9209-4b47-9ce5-e6d0f552f6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>vec</th>\n",
       "      <th>glo_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.033511575, 0.017874392, -0.12182923, 0.0465...</td>\n",
       "      <td>[-0.06319991304347827, 0.09004426086956521, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.042986494, 0.22736022, -0.048771024, 0.053...</td>\n",
       "      <td>[-0.16120359999999997, -0.016441500000000008, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.20488231, 0.004869846, -0.23974332, 0.0255...</td>\n",
       "      <td>[-0.2687100476190477, 0.1700534895238095, 0.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.03875695, 0.10936845, -0.21767448, 0.00962...</td>\n",
       "      <td>[-0.18971845384615385, 0.20216402692307683, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.087694, 0.12292659, -0.1436986, 0.08244420...</td>\n",
       "      <td>[-0.28627062, 0.387602, 0.24465479999999995, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  explanation edits made username hardcore metal...      0             0   \n",
       "1  aww match background colour seemingly stuck th...      0             0   \n",
       "2  hey man really trying edit war guy constantly ...      0             0   \n",
       "3  make real suggestion improvement wondered sect...      0             0   \n",
       "4                      sir hero chance remember page      0             0   \n",
       "\n",
       "                                                 vec  \\\n",
       "0  [0.033511575, 0.017874392, -0.12182923, 0.0465...   \n",
       "1  [-0.042986494, 0.22736022, -0.048771024, 0.053...   \n",
       "2  [-0.20488231, 0.004869846, -0.23974332, 0.0255...   \n",
       "3  [-0.03875695, 0.10936845, -0.21767448, 0.00962...   \n",
       "4  [-0.087694, 0.12292659, -0.1436986, 0.08244420...   \n",
       "\n",
       "                                             glo_vec  \n",
       "0  [-0.06319991304347827, 0.09004426086956521, 0....  \n",
       "1  [-0.16120359999999997, -0.016441500000000008, ...  \n",
       "2  [-0.2687100476190477, 0.1700534895238095, 0.33...  \n",
       "3  [-0.18971845384615385, 0.20216402692307683, 0....  \n",
       "4  [-0.28627062, 0.387602, 0.24465479999999995, -...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e95f38e1-6e9f-446d-9050-b56c2ba43c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['glo_vec']\n",
    "y = df['toxic']\n",
    "X = np.concatenate(X, axis = 0).reshape(-1, vec_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2dadaa80-d16b-4b7d-a5ea-3915f51ad607",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058db49-66cc-40a9-9e92-6a4d9b08bead",
   "metadata": {},
   "source": [
    "## 2.3.1 Linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3877a388-d5aa-43aa-820b-5cccdf0b3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f3df511f-15a7-41ec-a1dd-a08e8a0c074e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "824f6edf-aafc-4e9e-a483-9cd043bceddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6899b7d5-4fed-4c5b-add5-95a10fdcd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert continuous values to binary\n",
    "predictions[predictions >= 0.5] = 1\n",
    "predictions[predictions < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "47781eca-f157-4bfb-a909-048ec94051ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     28856\n",
      "           1       0.87      0.29      0.43      3059\n",
      "\n",
      "    accuracy                           0.93     31915\n",
      "   macro avg       0.90      0.64      0.70     31915\n",
      "weighted avg       0.92      0.93      0.91     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d12958c3-7adb-4b1c-965f-c302484233a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28724   132]\n",
      " [ 2176   883]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcab719-2848-4dbf-b2e7-a8d330967e8d",
   "metadata": {},
   "source": [
    "The model is bad because it has very low recall. Although the accuracy is 0.93."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b6af0-1cf7-477f-96a8-ac8d71760468",
   "metadata": {},
   "source": [
    "## 2.3.2 Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6a533c7f-74d9-4e6f-81f1-46938299be65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regressor = LogisticRegression(random_state=0)\n",
    "\n",
    "logistic_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "521198ae-fe6e-4cb0-a8ac-af59e51e5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e8c55abc-64ea-4918-b804-866306d161dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     28856\n",
      "           1       0.76      0.45      0.57      3059\n",
      "\n",
      "    accuracy                           0.93     31915\n",
      "   macro avg       0.85      0.72      0.77     31915\n",
      "weighted avg       0.93      0.93      0.93     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "da3efc3b-9828-4908-b3c5-306c8addc5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28418   438]\n",
      " [ 1673  1386]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991436b-b574-4373-898d-d46941df7cd6",
   "metadata": {},
   "source": [
    "Logistic regression performs much better compared to linear one. But the performance is still not good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1954194-8b0e-4bb0-a332-b9cdbed74087",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3.3 Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "20fdf472-da15-4aec-9030-aa8401e4fbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92     28856\n",
      "           1       0.39      0.65      0.49      3059\n",
      "\n",
      "    accuracy                           0.87     31915\n",
      "   macro avg       0.67      0.77      0.70     31915\n",
      "weighted avg       0.91      0.87      0.88     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB = BernoulliNB()\n",
    "\n",
    "NB.fit(X_train, y_train)\n",
    "predictions = NB.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fb4988af-3b0b-4506-994a-3a99cb6ffc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25675  3181]\n",
      " [ 1060  1999]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f750e4c-8bcf-4c5e-b9d5-efb6b5c00e28",
   "metadata": {},
   "source": [
    "I have got a very low precision with NB. Even accuracy is low (0.87)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e935750-1baa-4ff1-aede-d70c1513836e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3.4 Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8c382075-2bb1-4fbe-b2e4-cc5cc7794aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dad98cc0-51db-4b0d-9e17-c994c358dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': np.arange(1,10),\n",
    "             'criterion': ['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6b16cf49-d560-4803-946f-e140fe309b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(tree, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6cef7c99-687c-4e11-a79f-b2632162f540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([1, 2, 3, 4, 5, 6, 7, 8, 9])})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6a81134b-48ca-4e3f-8812-b308b24ba31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 7}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f6aff-4993-47d7-9cf3-1e0fffe9aba6",
   "metadata": {},
   "source": [
    "Grid search found that entropy criterion and a depth of 7 layers are the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1ea83db7-804e-4b8e-8058-f1026c0aeb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d23128a7-4511-44f2-88ba-77a34bef378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     28856\n",
      "           1       0.69      0.28      0.40      3059\n",
      "\n",
      "    accuracy                           0.92     31915\n",
      "   macro avg       0.81      0.63      0.68     31915\n",
      "weighted avg       0.91      0.92      0.90     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "38500d48-70cf-4ed2-b673-efff2d6b64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28479   377]\n",
      " [ 2201   858]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0abab1-888c-412f-a7fd-dedea5778d08",
   "metadata": {},
   "source": [
    "Recall and precision are very low in a tree model (0.28 and 0.69 respectively)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d180e-6373-4e8d-b2b8-bcc087e8869d",
   "metadata": {},
   "source": [
    "## 2.3.5 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ce7ffacf-6c57-4ef9-be24-ff2a36e85a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "360b807b-b9bb-4579-aa81-bdce6665c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': [1,5,10,15,20,25,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "028aa02e-46c9-4f7d-bb20-3708d79cb68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ad0b39ee-4f37-4f0f-9922-c9b38a34cbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 5, 10, 15, 20, 25, 30]})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bec34892-4475-4b93-824d-ac091a76d206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 20}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1c643477-962e-4e2b-a97f-a1a65ee481ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "316e6827-2698-4c50-a3fb-2c7acecee3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     28856\n",
      "           1       0.76      0.47      0.58      3059\n",
      "\n",
      "    accuracy                           0.94     31915\n",
      "   macro avg       0.85      0.73      0.77     31915\n",
      "weighted avg       0.93      0.94      0.93     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "af8dec56-760e-465b-a3b9-09b0b88da367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28404   452]\n",
      " [ 1618  1441]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39516c50-72b3-488a-a1a9-292c9218e9b4",
   "metadata": {},
   "source": [
    "In KNN, precision is low as well (0.76)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd989c-6bb7-4ba0-93d0-a057d88426e2",
   "metadata": {},
   "source": [
    "## 2.3.6 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d4439c0e-4774-4096-af55-2849bf1f1c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     28856\n",
      "           1       0.80      0.41      0.54      3059\n",
      "\n",
      "    accuracy                           0.93     31915\n",
      "   macro avg       0.87      0.70      0.75     31915\n",
      "weighted avg       0.93      0.93      0.92     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "predictions = svc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,  predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c52c4b25-189f-4a33-8982-22e61a8410b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28545   311]\n",
      " [ 1813  1246]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b120be90-38e0-4273-9121-e5193eb0a79b",
   "metadata": {},
   "source": [
    "SVC provides not the best results as well.\n",
    "\n",
    "Overall, for GloVe, linear regression (2.3.1) has the best performance with 0.87 precision and 0.93 accuracy.\n",
    "\n",
    "Out of all 18 models, TF-IDF logistic regression has the best performance with 0.93 precision and 0.96 accuracy.\n",
    "Let's save the model and check couple of comments on whether they are toxic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186c1a1-1a8c-4b63-9bb7-fa661f78c5a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c3ff6484-25dc-4c66-b744-5a6db3f82e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, df['toxic'], test_size=0.2, random_state=1, stratify = df['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "eb3163da-ed7a-4bd4-b603-168c494a9b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regressor = LogisticRegression(random_state=0)\n",
    "\n",
    "logistic_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3cf8c3ca-488c-4a36-84cf-d1d4c81001bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a39f79ef-6ef7-4fd7-a720-918c4c24aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "pickle.dump(logistic_regressor, open('log_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfb926f-0091-4e56-ba34-bf810f50adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ffa7fff-f385-41e3-ab1d-0f6fb7db26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = pickle.load(open('log_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cca07b-6d22-4112-ab91-5e6e6a95879e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12ecc799-3956-4e6e-8a7e-d4350c13ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(s):\n",
    "    x = []\n",
    "    x.append(s)\n",
    "    x[0] = preprocessing_text(x[0])\n",
    "    vec = vectorizer.transform(x)\n",
    "    label = model.predict(vec)[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798fd5d-7a2f-4207-8510-c361b45da923",
   "metadata": {},
   "source": [
    "Function above returns 1 if the message is classified toxic and 0 otherwise. For input it takes string, which is then preprocessed and converted to vector.\n",
    "\n",
    "Let's check some comments and see whether they are classified as toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123f48b6-1cc8-46ca-9e7d-76e4424e5577",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9748/3761765710.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Love you\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9748/485130959.py\u001b[0m in \u001b[0;36mget_pred\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "get_pred(\"Love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5beb2a8e-6f35-411f-92f8-c1f4857dd769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"I hate you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a9797f73-a601-4ec6-925b-45519dac89e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"Hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a73fe961-938a-4ab9-bc47-c805d16f9358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"Hate is normal, but we need to get better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5c6ed835-fcc6-41c3-9a7e-87a369f52035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"I would suggest you to cut off internet and jump off the roof\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05e949-35c6-4a1e-8175-b5b5c405b095",
   "metadata": {},
   "source": [
    "We get good predictions most of the time. However, the model sometimes ignores toxic messages and consider them non-toxic. This is because the recall is low. But we focused on precision, because we want the model to classify message as toxic only if it is really toxic.\n",
    "\n",
    "Let's import chat messages from Dota2 and check how many messages are toxic there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a48a38-e93f-43dd-9e53-cacf3c55db55",
   "metadata": {},
   "source": [
    "# 4. Dota 2 game chat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b9236957-4b04-4945-8994-bd673468e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = pd.read_csv('chat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a164a039-1e5c-496c-962d-25a7f4641cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>match_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>slot</th>\n",
       "      <th>time</th>\n",
       "      <th>unit</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>force it</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>6k Slayer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>space created</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Monkey</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>hah</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Monkey</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ez 500</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6k Slayer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>mvp ulti</td>\n",
       "      <td>4</td>\n",
       "      <td>934</td>\n",
       "      <td>Kira</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  match_id   comment_text  slot  time       unit  id\n",
       "0           0         0       force it     6    -8  6k Slayer   1\n",
       "1           1         0  space created     1     5     Monkey   2\n",
       "2           2         0            hah     1     6     Monkey   3\n",
       "3           3         0         ez 500     6     9  6k Slayer   4\n",
       "4           4         0       mvp ulti     4   934       Kira   5"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461b470-901c-4735-8ee4-ef22cddad8d4",
   "metadata": {},
   "source": [
    "The important columns that I will use are match_id, comment_text, and slot.\n",
    "* match_id is an ID of the match, there are 50k matches, I will use only first 5k matches just to check.\n",
    "* comment_text is a chat message\n",
    "* slot is a player slot. There are 10 players so slot column ranges from 0 to 9.\n",
    "\n",
    "For each game, I am going to have 10 documents, all messages sent from each of a player.\n",
    "\n",
    "Then, I am going to create a column toxic which will identify whether the player was toxic.\n",
    "\n",
    "> By creating a column toxic I assume that the dota2 comments are similar to Wikipedia comments that the model were trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d38b0511-989f-4f03-bec1-52859154b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "chat = chat.drop(['Unnamed: 0', 'time', 'unit', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1df8b-7529-4e69-b92e-272390bc32a6",
   "metadata": {},
   "source": [
    "Let's check the values of slot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4838d6c0-5ddf-4866-a20c-c09b3c7ed6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slot\n",
       "-9         4\n",
       " 0    149898\n",
       " 1    141096\n",
       " 2    140451\n",
       " 3    142879\n",
       " 4    140744\n",
       " 5    151895\n",
       " 6    141741\n",
       " 7    144117\n",
       " 8    143298\n",
       " 9    143365\n",
       "dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.groupby(['slot']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "91492e1b-796a-4fa9-8e3d-ed9a1251825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove slot -9 (assume those are mistakes)\n",
    "chat = chat[chat.slot != -9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15ee0f-bcd7-44a4-8443-74391f146826",
   "metadata": {},
   "source": [
    "Now let's reduce the df to only 5000 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8f072e66-6411-462a-b802-a18a7e4292ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = chat[chat.match_id < 5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ea2df-971e-47fd-9c34-db7f88922f4c",
   "metadata": {},
   "source": [
    "Now we can transform the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "96127a46-ecc8-472b-bc64-81da88634333",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = chat.groupby(['match_id', 'slot'])['comment_text'].apply(' '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "042f05d3-ec12-468f-9170-aed9d2eb3ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>slot</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fuck my ass ka bu tooooooooooooo 6k slayer haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>space created hah hah wtf TA? u srsly? why aly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>lol really ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>mvp ulti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>force it ez 500 bye fate is cruel sad spec noe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  slot                                       comment_text\n",
       "0         0     0    fuck my ass ka bu tooooooooooooo 6k slayer haha\n",
       "1         0     1  space created hah hah wtf TA? u srsly? why aly...\n",
       "2         0     2                                       lol really ?\n",
       "3         0     4                                           mvp ulti\n",
       "4         0     6  force it ez 500 bye fate is cruel sad spec noe..."
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09103e6b-d698-43be-911a-257c691a1de0",
   "metadata": {},
   "source": [
    "So, now we concatenated all the messages by each player in each game. We can assess whether player in a game was toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1f1fd4e1-07e3-4b0f-9dc5-fcf950f44174",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['toxic'] = chat['comment_text'].apply(lambda x: get_pred(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "daa6aecd-ddbc-4276-988f-b29b62a9ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    26738\n",
       "1     3618\n",
       "dtype: int64"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.groupby(['toxic']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a63ad-05b0-4bc1-8325-3e31baa3efc8",
   "metadata": {},
   "source": [
    "What we now have is that 3618 out of 30,356 players (those are the ones who wrote at least something in the chat. Ideally there should be 50,000 players (5,000 games x 10 players in each)) were toxic. That is about 10% of a selected games.\n",
    "\n",
    "Let's have a brief look on the toxic comments:\n",
    "> IMPORTANT: data contains text that may be considered profane, vulgar, or offensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b97c56cc-84d7-4137-8def-0aacc6398779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>slot</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>space created hah hah wtf TA? u srsly? why aly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>lol really ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>mvp ulti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>force it ez 500 bye fate is cruel sad spec noe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>wat that one i cant even run everyone kiting m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>our eshaker afk it will be abandoned he say sl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>HE WANT SLEEP HAHA ULTI ZEUS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>lol gege</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4 v 4 he lost hope</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>gg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>commend the solo supp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>why he afk ya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no not my problem...i guess XD we will wait XD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>not my prob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>wow u can play early game heros gg wp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1 min not my problem i love this life love u l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>w8 1 min plz gg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>ok dude WP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>so kind of you i dont hear somthing from clock...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>gg wp Gg wp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    match_id  slot                                       comment_text  toxic\n",
       "1          0     1  space created hah hah wtf TA? u srsly? why aly...      0\n",
       "2          0     2                                       lol really ?      0\n",
       "3          0     4                                           mvp ulti      0\n",
       "4          0     6  force it ez 500 bye fate is cruel sad spec noe...      0\n",
       "5          0     7  wat that one i cant even run everyone kiting m...      0\n",
       "7          1     1  our eshaker afk it will be abandoned he say sl...      0\n",
       "8          1     2                       HE WANT SLEEP HAHA ULTI ZEUS      0\n",
       "9          1     3                                           lol gege      0\n",
       "10         1     4                                 4 v 4 he lost hope      0\n",
       "11         1     5                                                 gg      0\n",
       "12         1     7                              commend the solo supp      0\n",
       "13         1     9                                      why he afk ya      0\n",
       "14         2     0  no not my problem...i guess XD we will wait XD...      0\n",
       "15         2     2                                        not my prob      0\n",
       "16         2     3              wow u can play early game heros gg wp      0\n",
       "17         2     5  1 min not my problem i love this life love u l...      0\n",
       "18         2     7                                   w8 1 min plz gg       0\n",
       "19         2     8                                         ok dude WP      0\n",
       "20         2     9  so kind of you i dont hear somthing from clock...      0\n",
       "21         3     1                                        gg wp Gg wp      0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat[chat['toxic']==0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb789fc-d081-4974-940d-f110d8bbe73d",
   "metadata": {},
   "source": [
    "Apparently, the comments contain profane words.\n",
    "\n",
    "Overall, I think I have a good model which predicts whether the text is toxic. And the model is doing this fast. One implementation of a model could be in any online community with comments. Thus, whether the person writes a toxic message, my model could send a preventive notification like \"The message might contain toxicity. You may need to reconsider the content of your message.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
